For homework 10, we had to fill in the PINN_Burgers jupyter notebook from class (12/4) and read the article: "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" by Emily M. Bender, Timnit Gebru, Angelica McMillan-Major, and Schmargaret Shmitchell (2021). 

On the coding assignement: We had to finish the notebook on phyiscally informed neural networks which was centered around Burger's Equations. To complete this portion of the assignment, I worked alongside Dr. Bianco's 12/4 class recording (https://udel.instructure.com/courses/1735534/external_tools/151642).

On the paper: The authors lay out a guide for evaluating the cost of large language models (LMs) which includes considering:
1. Environmental risk (running large models is damaging to the environment and this impacts marginalized communities much more)
2. Opacity of the data (too-large a training set may obfuscate and strengthen biases in the data)
3. Neccessity of big datasets (can a smaller dataset with a better trained algorithm yeild better results than a big dataset with only cursory/topical analysis?)

They then follow points researchers should consider when developing these dataset. Some of these include incorporating energy and efficiency in their model evaluations, thoughtful documentation of the data and its uses, and a re-alignment of research goals from size and score (to arbitrary tasks) to "understanding how machines are achieving".
